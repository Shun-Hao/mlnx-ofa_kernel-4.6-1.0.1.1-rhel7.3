From: Talat Batheesh <talatb@mellanox.com>
Subject: [PATCH] BACKPORT: drivers/net/ethernet/mellanox/mlx5/core/en/xdp.c

Change-Id: I2b2d6b9f70609955b215ccd167e9a5cd09a1db53
---
 drivers/net/ethernet/mellanox/mlx5/core/en/xdp.c | 110 +++++++++++++++++++++++
 1 file changed, 110 insertions(+)

diff --git a/drivers/net/ethernet/mellanox/mlx5/core/en/xdp.c b/drivers/net/ethernet/mellanox/mlx5/core/en/xdp.c
index xxxxxxx..xxxxxxx 100644
--- a/drivers/net/ethernet/mellanox/mlx5/core/en/xdp.c
+++ b/drivers/net/ethernet/mellanox/mlx5/core/en/xdp.c
@@ -30,6 +30,7 @@
  * SOFTWARE.
  */
 
+#ifdef HAVE_XDP_BUFF
 #include <linux/bpf_trace.h>
 #include "en/xdp.h"
 
@@ -57,21 +58,31 @@ bool mlx5e_xdp_handle(struct mlx5e_rq *rq, struct mlx5e_dma_info *di,
 	struct bpf_prog *prog = READ_ONCE(rq->xdp_prog);
 	struct xdp_buff xdp;
 	u32 act;
+#ifdef HAVE_XDP_REDIRECT
 	int err;
+#endif
 
 	if (!prog)
 		return false;
 
 	xdp.data = va + *rx_headroom;
+#ifdef HAVE_XDP_SET_DATA_META_INVALID
 	xdp_set_data_meta_invalid(&xdp);
+#endif
 	xdp.data_end = xdp.data + *len;
+#ifdef HAVE_XDP_BUFF_DATA_HARD_START
 	xdp.data_hard_start = va;
+#endif
+#ifdef HAVE_NET_XDP_H
 	xdp.rxq = &rq->xdp_rxq;
+#endif
 
 	act = bpf_prog_run_xdp(prog, &xdp);
 	switch (act) {
 	case XDP_PASS:
+#ifdef HAVE_XDP_BUFF_DATA_HARD_START
 		*rx_headroom = xdp.data - xdp.data_hard_start;
+#endif
 		*len = xdp.data_end - xdp.data;
 		return false;
 	case XDP_TX:
@@ -79,6 +90,7 @@ bool mlx5e_xdp_handle(struct mlx5e_rq *rq, struct mlx5e_dma_info *di,
 			goto xdp_abort;
 		__set_bit(MLX5E_RQ_FLAG_XDP_XMIT, rq->flags); /* non-atomic */
 		return true;
+#ifdef HAVE_XDP_REDIRECT
 	case XDP_REDIRECT:
 		/* When XDP enabled then page-refcnt==1 here */
 		err = xdp_do_redirect(rq->netdev, &xdp, prog);
@@ -89,13 +101,16 @@ bool mlx5e_xdp_handle(struct mlx5e_rq *rq, struct mlx5e_dma_info *di,
 		mlx5e_page_dma_unmap(rq, di);
 		rq->stats->xdp_redirect++;
 		return true;
+#endif
 	default:
 		bpf_warn_invalid_xdp_action(act);
 		/* fall through */
 	case XDP_ABORTED:
 xdp_abort:
+#if defined(HAVE_TRACE_XDP_EXCEPTION) && !defined(MLX_DISABLE_TRACEPOINTS)
 		trace_xdp_exception(rq->netdev, prog, act);
 		/* fall through */
+#endif
 	case XDP_DROP:
 		rq->stats->xdp_drop++;
 		return true;
@@ -173,7 +188,9 @@ bool mlx5e_poll_xdpsq_cq(struct mlx5e_cq *cq)
 	struct mlx5e_xdpsq *sq;
 	struct mlx5_cqe64 *cqe;
 	struct mlx5e_rq *rq;
+#ifdef HAVE_XDP_REDIRECT
 	bool is_redirect;
+#endif
 	u16 sqcc;
 	int i;
 
@@ -186,7 +203,9 @@ bool mlx5e_poll_xdpsq_cq(struct mlx5e_cq *cq)
 	if (!cqe)
 		return false;
 
+#ifdef HAVE_XDP_REDIRECT
 	is_redirect = test_bit(MLX5E_SQ_STATE_REDIRECT, &sq->state);
+#endif
 	rq = container_of(sq, struct mlx5e_rq, xdpsq);
 
 	/* sq->cc must be updated only after mlx5_cqwq_update_db_record(),
@@ -210,11 +229,20 @@ bool mlx5e_poll_xdpsq_cq(struct mlx5e_cq *cq)
 			last_wqe = (sqcc == wqe_counter);
 			sqcc++;
 
+#ifdef HAVE_XDP_REDIRECT
 			if (is_redirect) {
+#ifdef HAVE_XDP_FRAME
 				xdp_return_frame(xdpi->xdpf);
+#else
+				/* Assumes order0 page*/
+				put_page(virt_to_page(xdpi->xdpf->data));
+#endif
 				dma_unmap_single(sq->pdev, xdpi->dma_addr,
 						 xdpi->xdpf->len, DMA_TO_DEVICE);
 			} else {
+#else
+			{
+#endif
 				/* Recycle RX page */
 				mlx5e_page_release(rq, &xdpi->di, true);
 			}
@@ -235,10 +263,16 @@ bool mlx5e_poll_xdpsq_cq(struct mlx5e_cq *cq)
 void mlx5e_free_xdpsq_descs(struct mlx5e_xdpsq *sq)
 {
 	struct mlx5e_rq *rq;
+#ifdef HAVE_XDP_REDIRECT
 	bool is_redirect;
+#endif
 
+#ifdef HAVE_XDP_REDIRECT
 	is_redirect = test_bit(MLX5E_SQ_STATE_REDIRECT, &sq->state);
 	rq = is_redirect ? NULL : container_of(sq, struct mlx5e_rq, xdpsq);
+#else
+	rq = container_of(sq, struct mlx5e_rq, xdpsq);
+#endif
 
 	while (sq->cc != sq->pc) {
 		u16 ci = mlx5_wq_cyc_ctr2ix(&sq->wq, sq->cc);
@@ -246,17 +280,28 @@ void mlx5e_free_xdpsq_descs(struct mlx5e_xdpsq *sq)
 
 		sq->cc++;
 
+#ifdef HAVE_XDP_REDIRECT
 		if (is_redirect) {
+#ifdef HAVE_XDP_FRAME
 			xdp_return_frame(xdpi->xdpf);
+#else
+			/* Assumes order0 page*/
+			put_page(virt_to_page(xdpi->xdpf->data));
+#endif
 			dma_unmap_single(sq->pdev, xdpi->dma_addr,
 					 xdpi->xdpf->len, DMA_TO_DEVICE);
 		} else {
+#else
+		{
+#endif
 			/* Recycle RX page */
 			mlx5e_page_release(rq, &xdpi->di, false);
 		}
 	}
 }
 
+#ifdef HAVE_NDO_XDP_XMIT
+#ifndef HAVE_NDO_XDP_FLUSH
 int mlx5e_xdp_xmit(struct net_device *dev, int n, struct xdp_frame **frames,
 		   u32 flags)
 {
@@ -295,9 +340,14 @@ int mlx5e_xdp_xmit(struct net_device *dev, int n, struct xdp_frame **frames,
 		xdpi.xdpf = xdpf;
 
 		if (unlikely(!mlx5e_xmit_xdp_frame(sq, &xdpi))) {
+#ifdef HAVE_XDP_FRAME
 			dma_unmap_single(sq->pdev, xdpi.dma_addr,
 					 xdpf->len, DMA_TO_DEVICE);
 			xdp_return_frame_rx_napi(xdpf);
+#else
+			/* Assumes order0 page*/
+			put_page(virt_to_page(xdpf->data));
+#endif
 			drops++;
 		}
 	}
@@ -307,3 +357,63 @@ int mlx5e_xdp_xmit(struct net_device *dev, int n, struct xdp_frame **frames,
 
 	return n - drops;
 }
+#else
+int mlx5e_xdp_xmit(struct net_device *dev, struct xdp_buff *xdp)
+{
+	struct mlx5e_priv *priv = netdev_priv(dev);
+	struct mlx5e_xdp_info xdpi;
+	struct mlx5e_xdpsq *sq;
+	int sq_num;
+
+	if (unlikely(!test_bit(MLX5E_STATE_OPENED, &priv->state)))
+		return -ENETDOWN;
+
+	sq_num = smp_processor_id();
+
+	if (unlikely(sq_num >= priv->channels.num))
+		return -ENXIO;
+
+	sq = &priv->channels.c[sq_num]->xdpsq;
+
+	if (unlikely(!test_bit(MLX5E_SQ_STATE_ENABLED, &sq->state)))
+		return -ENETDOWN;
+
+	xdpi.xdpf = convert_to_xdp_frame(xdp);
+	if (unlikely(!xdpi.xdpf))
+		return -ENOSPC;
+
+	xdpi.dma_addr = dma_map_single(sq->pdev, xdpi.xdpf->data,
+				       xdpi.xdpf->len, DMA_TO_DEVICE);
+	if (unlikely(dma_mapping_error(sq->pdev, xdpi.dma_addr)))
+		return -ENOSPC;
+
+	if (unlikely(!mlx5e_xmit_xdp_frame(sq, &xdpi)))
+		return -ENOSPC;
+
+	return 0;
+}
+
+void mlx5e_xdp_flush(struct net_device *dev)
+{
+	struct mlx5e_priv *priv = netdev_priv(dev);
+	struct mlx5e_xdpsq *sq;
+	int sq_num;
+
+	if (unlikely(!test_bit(MLX5E_STATE_OPENED, &priv->state)))
+		return;
+
+	sq_num = smp_processor_id();
+
+	if (unlikely(sq_num >= priv->channels.num))
+		return;
+
+	sq = &priv->channels.c[sq_num]->xdpsq;
+
+	if (unlikely(!test_bit(MLX5E_SQ_STATE_ENABLED, &sq->state)))
+		return;
+
+	mlx5e_xmit_xdp_doorbell(sq);
+}
+#endif
+#endif
+#endif
