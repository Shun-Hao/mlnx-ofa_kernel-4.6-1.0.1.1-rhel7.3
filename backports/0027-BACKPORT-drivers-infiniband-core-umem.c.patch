From: Talat Batheesh <talatb@mellanox.com>
Subject: [PATCH] BACKPORT: drivers/infiniband/core/umem.c

Change-Id: I38d6d4d8c2488ca8da3e5bcb2ebf20f5286beb04
---
 drivers/infiniband/core/umem.c | 57 ++++++++++++++++++++++++++++++++++++++++++
 1 file changed, 57 insertions(+)

diff --git a/drivers/infiniband/core/umem.c b/drivers/infiniband/core/umem.c
index xxxxxxx..xxxxxxx 100644
--- a/drivers/infiniband/core/umem.c
+++ b/drivers/infiniband/core/umem.c
@@ -193,12 +193,22 @@ struct ib_umem *ib_umem_get(struct ib_ucontext *context, unsigned long addr,
 	unsigned long npages;
 	int ret;
 	int i;
+#ifdef HAVE_STRUCT_DMA_ATTRS
+	DEFINE_DMA_ATTRS(attrs);
+#else
 	unsigned long dma_attrs = 0;
+#endif
 	struct scatterlist *sg, *sg_list_start;
+#ifdef HAVE_GET_USER_PAGES_GUP_FLAGS
 	unsigned int gup_flags = FOLL_WRITE;
+#endif
 
 	if (dmasync)
+#ifdef HAVE_STRUCT_DMA_ATTRS
+		dma_set_attr(DMA_ATTR_WRITE_BARRIER, &attrs);
+#else
 		dma_attrs |= DMA_ATTR_WRITE_BARRIER;
+#endif
 
 	/*
 	 * If the combination of the addr and size requested for this memory
@@ -276,15 +286,22 @@ struct ib_umem *ib_umem_get(struct ib_ucontext *context, unsigned long addr,
 	lock_limit = rlimit(RLIMIT_MEMLOCK) >> PAGE_SHIFT;
 
 	down_write(&mm->mmap_sem);
+#ifdef HAVE_PINNED_VM
 	if (check_add_overflow(mm->pinned_vm, npages, &new_pinned) ||
 	    (new_pinned > lock_limit && !capable(CAP_IPC_LOCK))) {
+#else
+	current->mm->locked_vm += npages;
+	if ((current->mm->locked_vm > lock_limit) && !capable(CAP_IPC_LOCK)) {
+#endif
 		up_write(&mm->mmap_sem);
 		pr_debug("%s: requested to lock(%lu) while limit is(%lu)\n",
 		       __func__, new_pinned, lock_limit);
 		ret = -ENOMEM;
 		goto out;
 	}
+#ifdef HAVE_PINNED_VM
 	mm->pinned_vm = new_pinned;
+#endif
 	up_write(&mm->mmap_sem);
 
 	cur_base = addr & PAGE_MASK;
@@ -296,22 +313,46 @@ struct ib_umem *ib_umem_get(struct ib_ucontext *context, unsigned long addr,
 		goto vma;
 	}
 
+#ifdef HAVE_GET_USER_PAGES_GUP_FLAGS
 	if (!umem->writable)
 		gup_flags |= FOLL_FORCE;
+#endif
 
 	sg_list_start = umem->sg_head.sgl;
 
 	while (npages) {
 		down_read(&mm->mmap_sem);
+#ifdef HAVE_GET_USER_PAGES_8_PARAMS
+		ret = get_user_pages(current, current->mm, cur_base,
+				     min_t(unsigned long, npages,
+					   PAGE_SIZE / sizeof (struct page *)),
+				     1, !umem->writable, page_list, vma_list);
+#else
+#ifdef HAVE_GET_USER_PAGES_LONGTERM
 		ret = get_user_pages_longterm(cur_base,
+#else
+		ret = get_user_pages(cur_base,
+#endif
 				     min_t(unsigned long, npages,
 					   PAGE_SIZE / sizeof (struct page *)),
+#ifdef HAVE_GET_USER_PAGES_GUP_FLAGS
 				     gup_flags, page_list, vma_list);
+#else
+				     1, !umem->writable, page_list, vma_list);
+#endif
+#endif
 		if (ret < 0) {
+#ifdef HAVE_GET_USER_PAGES_GUP_FLAGS
 			pr_debug("%s: failed to get user pages, nr_pages=%lu, flags=%u\n", __func__,
 			       min_t(unsigned long, npages,
 				     PAGE_SIZE / sizeof(struct page *)),
 			       gup_flags);
+#else
+			pr_err("%s: failed to get user pages, nr_pages=%lu\n", __func__,
+			       min_t(unsigned long, npages,
+				     PAGE_SIZE / sizeof(struct page *)));
+#endif
+
 			up_read(&mm->mmap_sem);
 			goto umem_release;
 		}
@@ -339,7 +380,11 @@ struct ib_umem *ib_umem_get(struct ib_ucontext *context, unsigned long addr,
 				  umem->sg_head.sgl,
 				  umem->npages,
 				  DMA_BIDIRECTIONAL,
+#ifdef HAVE_STRUCT_DMA_ATTRS
+				  &attrs);
+#else
 				  dma_attrs);
+#endif
 
 	if (!umem->nmap) {
 		pr_err("%s: failed to map scatterlist, npages=%d\n", __func__,
@@ -355,7 +400,11 @@ umem_release:
 	__ib_umem_release(context->device, umem, 0);
 vma:
 	down_write(&mm->mmap_sem);
+#ifdef HAVE_PINNED_VM
 	mm->pinned_vm -= ib_umem_num_pages(umem);
+#else
+	mm->locked_vm -= ib_umem_num_pages(umem);
+#endif
 	up_write(&mm->mmap_sem);
 out:
 	if (vma_list)
@@ -406,7 +455,11 @@ static void ib_umem_release_defer(struct work_struct *work)
 	struct ib_umem *umem = container_of(work, struct ib_umem, work);
 
 	down_write(&umem->owning_mm->mmap_sem);
+#ifdef HAVE_PINNED_VM
 	umem->owning_mm->pinned_vm -= ib_umem_num_pages(umem);
+#else
+	umem->owning_mm->locked_vm -= ib_umem_num_pages(umem);
+#endif
 	up_write(&umem->owning_mm->mmap_sem);
 
 	__ib_umem_release_tail(umem);
@@ -450,7 +503,11 @@ void ib_umem_release(struct ib_umem *umem)
 	} else {
 		down_write(&umem->owning_mm->mmap_sem);
 	}
+#ifdef HAVE_PINNED_VM
 	umem->owning_mm->pinned_vm -= ib_umem_num_pages(umem);
+#else
+	umem->owning_mm->locked_vm -= ib_umem_num_pages(umem);
+#endif
 	up_write(&umem->owning_mm->mmap_sem);
 
 	__ib_umem_release_tail(umem);
